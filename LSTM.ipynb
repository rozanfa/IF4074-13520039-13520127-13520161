{"cells":[{"cell_type":"code","metadata":{"source_hash":"61d633bc","execution_start":1699022104374,"execution_millis":2293,"deepnote_to_be_reexecuted":false,"cell_id":"debeb8a993d747a6be55894b39d51731","deepnote_cell_type":"code"},"source":"!pip install prettytable","block_group":"356cc00b05ad461caeefd206894a8e42","execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: prettytable in /root/venv/lib/python3.9/site-packages (3.9.0)\nRequirement already satisfied: wcwidth in /shared-libs/python3.9/py-core/lib/python3.9/site-packages (from prettytable) (0.2.5)\n\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","metadata":{"source_hash":"57814848","execution_start":1699022106669,"execution_millis":13,"deepnote_to_be_reexecuted":false,"cell_id":"734ae5d970bb440681c909d5daa1193a","deepnote_cell_type":"code"},"source":"import numpy as np\nimport pandas as pd\nfrom math import sqrt\nimport json\n\ndef sigmoid(X):\n    \"\"\"Sigmoid activation function\"\"\"\n    return 1 / (1 + np.exp(-X))\n\ndef relu(X):\n    \"\"\"ReLU activation function\"\"\"\n    return np.maximum(0, X)\n\ndef tanh(X):\n    \"\"\"TanH activaction function\"\"\"\n    return np.tanh(X)","block_group":"734ae5d970bb440681c909d5daa1193a","execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"source_hash":"36228c02","execution_start":1699022106678,"execution_millis":10,"deepnote_to_be_reexecuted":false,"cell_id":"3aa11bbb82d74a6e8e2eddcd1c5d09e6","deepnote_cell_type":"code"},"source":"class Layer:\n    input_shape = None\n    output_shape = None\n    \n    def forward():\n        pass","block_group":"8bcbbb9190ba4f278f722601ccb44d54","execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"source_hash":"3fb4d5c2","execution_start":1699022106706,"execution_millis":37,"deepnote_to_be_reexecuted":false,"cell_id":"b29c9ab3f0154c238f8b946efb2fca8c","deepnote_cell_type":"code"},"source":"from typing import Literal\n\nclass LSTM(Layer):\n    class Weight:\n        \"\"\"Weight class for LSTM\"\"\"\n        def __init__(self, f, i, c, o) -> None:\n            self.f = f\n            self.i = i\n            self.c = c\n            self.o = o\n\n    def __init__(self, units: int) -> None:\n        super().__init__()\n        self.units = units\n\n    def _compile(self, input_shape: int, from_load: bool = False):\n        self.input_shape = input_shape # (Row, Feature)\n        self.output_shape = self.units\n        \n        self.weight = self.Weight(\n            np.random.randn(self.units, self.input_shape[1]),\n            np.random.randn(self.units, self.input_shape[1]),\n            np.random.randn(self.units, self.input_shape[1]),\n            np.random.randn(self.units, self.input_shape[1]))\n        \n        self.bias = self.Weight(\n            np.random.randn(self.units),\n            np.random.randn(self.units),\n            np.random.randn(self.units),\n            np.random.randn(self.units)) # b\n        \n        self.reccurent_weight = self.Weight(\n            np.random.randn(self.output_shape, self.output_shape),\n            np.random.randn(self.output_shape, self.output_shape),\n            np.random.randn(self.output_shape, self.output_shape),\n            np.random.randn(self.output_shape, self.output_shape)) # W\n        \n        self.timestep = np.zeros(self.units)\n        self.ct = np.zeros(self.units)\n        self.ht = np.zeros(self.units)\n\n        return self.output_shape\n\n    def forward(self, input_data: np.ndarray):\n        \"\"\"Forward propagation\"\"\"\n        \n        # Loop through all units:\n        for unit_idx in range(self.units):\n            # Loop through all rows\n            for row_idx in range(self.input_shape[0]):\n                # Calculate forget gate\n                ft = sigmoid(np.dot(self.weight.f[unit_idx], input_data[row_idx]) + np.dot(self.reccurent_weight.f[unit_idx], self.ht) + self.bias.f[unit_idx])\n                # Calculate input gate\n                it = sigmoid(np.dot(self.weight.i[unit_idx], input_data[row_idx]) + np.dot(self.reccurent_weight.i[unit_idx], self.ht) + self.bias.i[unit_idx])\n                # Calculate candidate\n                ct_ = tanh(np.dot(self.weight.c[unit_idx], input_data[row_idx]) + np.dot(self.reccurent_weight.c[unit_idx], self.ht) + self.bias.c[unit_idx])\n                # Calculate output gate\n                ot = sigmoid(np.dot(self.weight.o[unit_idx], input_data[row_idx]) + np.dot(self.reccurent_weight.o[unit_idx], self.ht) + self.bias.o[unit_idx])\n                \n                # Calculate cell state\n                self.ct[unit_idx] = ft * self.ct[unit_idx] + it * ct_\n\n                # Calculate hidden state\n                self.ht[unit_idx] = ot * tanh(self.ct[unit_idx])\n                self.timestep[unit_idx] += 1\n\n        return self.ht\n\n    def get_params_count(self):\n        return self.bias.f.size * 4 + self.weight.f.size * 4 + self.reccurent_weight.f.size * 4\n\n    def set_params(self, params):\n        self.weight.f = np.array(params[\"W_f\"])\n        self.weight.i = np.array(params[\"W_i\"])\n        self.weight.c = np.array(params[\"W_c\"])\n        self.weight.o = np.array(params[\"W_o\"])\n        self.reccurent_weight.f = np.array(params[\"U_f\"])\n        self.reccurent_weight.i = np.array(params[\"U_i\"])\n        self.reccurent_weight.c = np.array(params[\"U_c\"])\n        self.reccurent_weight.o = np.array(params[\"U_o\"])\n        self.bias.f = np.array(params[\"b_f\"])\n        self.bias.i = np.array(params[\"b_i\"])\n        self.bias.c = np.array(params[\"b_c\"])\n        self.bias.o = np.array(params[\"b_o\"])\n\n    def get_params(self):\n        params = {\n            \"units\": self.units,\n            \"W_i\": np.transpose(self.weight.i).tolist(),\n            \"W_f\": np.transpose(self.weight.f).tolist(),\n            \"W_c\": np.transpose(self.weight.c).tolist(),\n            \"W_o\": np.transpose(self.weight.o).tolist(),\n            \"U_i\": self.reccurent_weight.i.tolist(),\n            \"U_f\": self.reccurent_weight.f.tolist(),\n            \"U_c\": self.reccurent_weight.c.tolist(),\n            \"U_o\": self.reccurent_weight.o.tolist(),\n            \"b_i\": self.bias.i.tolist(),\n            \"b_f\": self.bias.f.tolist(),\n            \"b_c\": self.bias.c.tolist(),\n            \"b_o\": self.bias.o.tolist(),\n        }\n        return params\n\n\nif __name__ == \"__main__\":\n    model = LSTM(1)\n    model._compile((2, 2))\n    model.weight.f = np.array([[0.5, 0.75]])\n    model.weight.i = np.array([[0.81, 0.2]])\n    model.weight.c = np.array([[0.35, 0.45]])\n    model.weight.o = np.array([[0.4, 0.6]])\n    model.reccurent_weight.f = np.array([[0.3]])\n    model.reccurent_weight.i = np.array([[0.7]])\n    model.reccurent_weight.c = np.array([[0.35]])\n    model.reccurent_weight.o = np.array([[0.4]])\n    model.bias.f = np.array([0.4])\n    model.bias.i = np.array([0.55])\n    model.bias.c = np.array([0.25])\n    model.bias.o = np.array([0.5])\n    print(model.forward(np.array([[0.5, 3], [1, 2]])))\n\n    new_model = LSTM(64)\n    new_model._compile((4, 5))\n    print(new_model.weight.f.shape)\n    print(new_model.output_shape)","block_group":"918187936cf342e2a4fc2adccf46c92d","execution_count":4,"outputs":[{"name":"stdout","text":"[0.83602558]\n(64, 5)\n64\n","output_type":"stream"}]},{"cell_type":"code","metadata":{"source_hash":"da4345a7","execution_start":1699022106739,"execution_millis":46,"deepnote_to_be_reexecuted":false,"cell_id":"84a87f243fc6440f9b2e27a3f05d6884","deepnote_cell_type":"code"},"source":"class Dense(Layer):\n    def __init__(self, units: int, activation: Literal[\"sigmoid\", \"relu\"] = \"relu\") -> None:\n        \"\"\"\n        Dense layer\n\n        Parameters\n        ----------\n        units : int\n            Number of neuron\n        activation : str\n            Activation function (\"sigmoid\" or \"relu\")\n        \"\"\"\n        self.units = units\n        self.activation = activation\n\n        self.output_shape = units\n\n    def _compile(self, shape, from_load: bool = False):\n        # Initialize weight & bias\n        self.input_size = shape\n\n        if not from_load:\n            self.weights = np.random.randn(shape, self.units)\n            self.bias = np.random.randn(self.units)\n        \n        return self.output_shape\n\n    @staticmethod\n    def __activate(X: np.ndarray, activation: Literal[\"sigmoid\", \"relu\"] = \"relu\") -> np.ndarray:\n        \"\"\"Activation function\n\n        Parameters\n        ----------\n        X : np.ndarray\n            Input data\n        activation : str\n            Activation function to be used\n        \"\"\"\n        if activation == \"sigmoid\":\n            f = lambda x: sigmoid(x)\n        elif activation == \"relu\":\n            f = lambda x: relu(x)\n        else:\n            raise ValueError(\"Activation function not supported\")\n        return f(X)\n\n    def forward(self, input_data: np.ndarray) -> np.ndarray:\n        \"\"\"Forward pass of Dense layer\n\n        Parameters\n        ----------\n        input_data : np.ndarray\n            Input data to be passed through the layer\n        \"\"\"\n        \n        # Linear transformation (dot product input x weights)\n        self.input_data = input_data\n        self.output = np.dot(input_data, self.weights) + self.bias\n        \n        # Activation function\n        output = Dense.__activate(self.output, self.activation)\n        \n        return output\n\n    def get_params_count(self):\n        return self.input_size * self.units + self.units\n\n    def set_params(self, params):\n        self.weights = np.array(params[\"kernel\"])\n        self.bias = np.array(params[\"bias\"])\n\n    def get_params(self):\n        params = {\n            \"units\": self.units,\n            \"activation\": self.activation,\n            \"kernel\": self.weights.tolist(),\n            \"bias\": self.bias.tolist()\n        }\n        return params\n\n    def set_params(self, params):\n        self.units = params[\"units\"]\n        self.activation = params[\"activation\"]\n        self.weights = np.array(params[\"weights\"])\n        self.bias = np.array(params[\"bias\"])","block_group":"7b235ac1d2b94995b7d4d4bc35aba767","execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"source_hash":"a98700d5","execution_start":1699022106740,"execution_millis":47,"deepnote_to_be_reexecuted":false,"cell_id":"d27de66ad89947bca4194211394fcb8a","deepnote_cell_type":"code"},"source":"from prettytable import PrettyTable\n\nclass Sequential:\n    def __init__(self, layers: list[object] = []):\n        self.layers = layers\n\n    def add(self, layer: Layer) -> None:\n        self.layers.append(layer)\n\n    def forward(self, inp: np.ndarray) -> np.ndarray:\n        for layer in self.layers:\n            inp = layer.forward(inp)\n        return inp\n\n    def predict(self, img: np.ndarray) -> np.ndarray:\n        return self.forward(img)\n\n    def compile(self, input_shape, from_load: bool = False):\n        assert len(self.layers) > 0, \"Tambah layer terlebih dahulu\"\n        for layer in self.layers:\n            layer._compile(input_shape, from_load)\n            input_shape = layer.output_shape\n\n    def summary(self):\n        total_params = 0\n        print(\"Model Summary:\")\n\n        table = PrettyTable([\"Nama Layer\", \"Output Shape\", \"Parameter\"])\n        for i, layer in enumerate(self.layers):\n            layer_name = layer.__class__.__name__\n            output_shape = layer.output_shape if hasattr(layer, \"output_shape\") else None\n            params = layer.get_params_count() if hasattr(layer, \"get_params_count\") else 0\n            total_params += params\n            \n            table.add_row([layer_name, output_shape, params])\n\n        print(table)\n        print(f\"Total Parameters: {total_params}\")\n\n    # Save Model\n    def save_model(self, filepath):\n        model_dict = {\n            \"layers\": []\n        }\n        for layer in self.layers:\n            layer_dict = {\n                \"type\": layer.__class__.__name__,\n                \"params\": layer.get_params()\n            }\n            # Ensure input_shape is saved for LSTM layers\n            if isinstance(layer, LSTM):\n                layer_dict[\"params\"][\"input_shape\"] = layer.input_shape\n            model_dict[\"layers\"].append(layer_dict)\n\n        with open(filepath, 'w') as file:\n            json.dump(model_dict, file, indent=4)\n\n    def load_model(self, filename):\n        with open(filename, 'r') as json_file:\n            model_params = json.load(json_file)\n\n        layers = []\n        for layer_params in model_params:\n            layer_type = layer_params[\"type\"]\n            layer_args = layer_params[\"params\"]\n\n            if layer_type == \"dense\":\n                layer = Dense(units=layer_args[\"units\"], activation=layer_args[\"activation\"])\n            elif layer_type == \"lstm\":\n                # Check if 'input_shape' is in layer_args before trying to use it\n                if \"input_shape\" not in layer_args:\n                    raise KeyError(\"input_shape is required for LSTM layers.\")\n                \n                layer = LSTM(units=layer_args[\"units\"])\n                layer._compile(input_shape=layer_args[\"input_shape\"])\n                layer.set_params(layer_args)\n            else:\n                raise ValueError(f\"Unsupported layer type: {layer_type}\")\n\n            if \"input_shape\" in layer_params:\n                layer.input_shape = tuple(layer_params[\"input_shape\"])\n\n            layer.set_params(layer_args)\n            layers.append(layer)\n\n        return Sequential(layers)","block_group":"a5271b363c9a4bb2a03e0c0a4681aa57","execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"source_hash":"5eb963cd","execution_start":1699022106754,"execution_millis":32,"deepnote_to_be_reexecuted":false,"cell_id":"03aab19cc0144cef855235c4d9f3de27","deepnote_cell_type":"code"},"source":"# split for getting next day result\ndef split_sequence(sequence, n_steps):\n\tX, y = list(), list()\n\tfor i in range(len(sequence)):\n\t\t# find the end of this pattern\n\t\tend_ix = i + n_steps\n\t\t# check if we are beyond the sequence\n\t\tif end_ix > len(sequence)-1:\n\t\t\tbreak\n\t\t# gather input and output parts of the pattern\n\t\tseq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\n\t\tX.append(seq_x)\n\t\ty.append(seq_y)\n\treturn np.array(X), np.array(y)","block_group":"7cb6a6a4aa3b4ed59ec466488b865176","execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"source_hash":"c7511af6","execution_start":1699022106809,"execution_millis":8,"deepnote_to_be_reexecuted":false,"cell_id":"b1711d56be3042e590e474fe1534f921","deepnote_cell_type":"code"},"source":"raw_train = pd.read_csv(\"TubesRNN/Train_stock_market.csv\")\ntest = pd.read_csv(\"TubesRNN/Test_stock_market.csv\")\n\ntrain_date = raw_train[\"Date\"]\ntrain_date = pd.to_datetime(train_date)\n\ntrain = raw_train.drop(\"Date\", axis=1)\n\ntrain['Date'] = train_date\ntest['Date'] = pd.to_datetime(test['Date'])\n\n# print(test.head())\n# print(train.head())\n\n# Take relevant columns\ntrain = train[['Date', 'Open', 'High', 'Low', 'Close']]\ntest = test[['Date', 'Open', 'High', 'Low', 'Close']]","block_group":"da485cb58ab74ba2a35d94937e208325","execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"source_hash":"9bd7ef0e","execution_start":1699022106853,"execution_millis":10,"deepnote_to_be_reexecuted":false,"cell_id":"b5fae07bcab84f259ded3c95cb857198","deepnote_cell_type":"code"},"source":"# Experiment 1\nn_steps = 10  # Number of days\nX_train, y_train = split_sequence(train[['Open', 'High', 'Low', 'Close']].values, n_steps)\nX_test, y_test = split_sequence(test[['Open', 'High', 'Low', 'Close']].values, n_steps)\n\n# Create model\nmodel = Sequential([])\nmodel.add(LSTM(units=64))\nmodel.add(Dense(units=32, activation=\"relu\"))\nmodel.add(Dense(units=4))  # 4 output\n\ninput_shape = (X_test.shape[1], X_test.shape[2])  # (n_steps, number of features)\n\n# Compile\nmodel.compile(input_shape, from_load=False)","block_group":"60493412db924f678343b6667bc0fe39","execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"cell_id":"c4cf8b1b2f1c4becad5dccb62d77f37a","deepnote_cell_type":"code"},"source":"# Experiment 2\nn_steps_2 = 35  # Number of days\nX_train_2, y_train_2 = split_sequence(train[['Open', 'High', 'Low', 'Close']].values, n_steps_2)\nX_test_2, y_test_2 = split_sequence(test[['Open', 'High', 'Low', 'Close']].values, n_steps_2)\n\n# Create model\nmodel_2 = Sequential([])\nmodel_2.add(LSTM(units=64))\nmodel_2.add(LSTM(units=128))\nmodel_2.add(LSTM(units=32))\nmodel_2.add(Dense(units=32, activation=\"relu\"))\nmodel_2.add(Dense(units=4))  # 4 output\n\ninput_shape_2 = (X_test.shape[1], X_test.shape[2])  # (n_steps, number of features)\n\n# Compile\nmodel_2.compile(input_shape_2, from_load=False)","block_group":"2f5c53908d774d9db6962a27c62c7015","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"source_hash":"8dc2f137","execution_start":1699022106854,"execution_millis":511,"deepnote_to_be_reexecuted":false,"cell_id":"90db603c07a64353b7c2c7c3687ace4c","deepnote_cell_type":"code"},"source":"model.save_model('TubesRNN/exp1.json')\nmodel_2.save_model('TubesRNN/exp2.json')\nmodel_3.save_model('TubesRNN/exp3.json')\n\nmodel_exp1 = Sequential([])\nmodel_exp1 = model_exp1.load_model('TubesRNN/exp1.json')\n\nmodel_exp2 = Sequential([])\nmodel_exp2 = model_exp2.load_model('TubesRNN/exp2.json')\n\nmodel_exp3 = Sequential([])\nmodel_exp3 = model_exp3.load_model('TubesRNN/exp3.json')","block_group":"151a0d7156334effaf4a4d75283cb154","execution_count":10,"outputs":[{"output_type":"error","ename":"TypeError","evalue":"string indices must be integers","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn [10], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m model\u001b[38;5;241m.\u001b[39msave_model(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTubesRNN/exp1.json\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m model_exp1 \u001b[38;5;241m=\u001b[39m Sequential([])\n\u001b[0;32m----> 3\u001b[0m model_exp1 \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_exp1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTubesRNN/exp1.json\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn [6], line 66\u001b[0m, in \u001b[0;36mSequential.load_model\u001b[0;34m(self, filename)\u001b[0m\n\u001b[1;32m     64\u001b[0m layers \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer_params \u001b[38;5;129;01min\u001b[39;00m model_params:\n\u001b[0;32m---> 66\u001b[0m     layer_type \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_params\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     67\u001b[0m     layer_args \u001b[38;5;241m=\u001b[39m layer_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m layer_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdense\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n","\u001b[0;31mTypeError\u001b[0m: string indices must be integers"]}]},{"cell_type":"code","metadata":{"source_hash":"15622590","execution_start":1699017709142,"execution_millis":15,"deepnote_to_be_reexecuted":true,"cell_id":"2ad5e86c7d214c4694bcc4be4475c723","deepnote_cell_type":"code"},"source":"# model.summary()\nmodel_exp1.summary()\nmodel_exp2.summary()\nmodel_exp2.summary()","block_group":"df5cd777e6904646bb83018b9dcdc294","execution_count":null,"outputs":[{"name":"stdout","text":"Model Summary:\n","output_type":"stream"},{"output_type":"error","ename":"AttributeError","evalue":"'Dense' object has no attribute 'input_size'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","Cell \u001b[0;32mIn [29], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# model.summary()\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mmodel_exp1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msummary\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn [6], line 33\u001b[0m, in \u001b[0;36mSequential.summary\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     31\u001b[0m layer_name \u001b[38;5;241m=\u001b[39m layer\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\n\u001b[1;32m     32\u001b[0m output_shape \u001b[38;5;241m=\u001b[39m layer\u001b[38;5;241m.\u001b[39moutput_shape \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(layer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_shape\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 33\u001b[0m params \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_params_count\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(layer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mget_params_count\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     34\u001b[0m total_params \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m params\n\u001b[1;32m     36\u001b[0m table\u001b[38;5;241m.\u001b[39madd_row([layer_name, output_shape, params])\n","Cell \u001b[0;32mIn [5], line 66\u001b[0m, in \u001b[0;36mDense.get_params_count\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_params_count\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m---> 66\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_size\u001b[49m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munits \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munits\n","\u001b[0;31mAttributeError\u001b[0m: 'Dense' object has no attribute 'input_size'"]}]},{"cell_type":"code","metadata":{"source_hash":"df841cc9","execution_start":1699017960056,"execution_millis":352,"deepnote_to_be_reexecuted":true,"cell_id":"bfbfd2af92d847a78b17899443d8fac9","deepnote_cell_type":"code"},"source":"predictions = []\nrmses = []\nfor i in range(len(X_test)):\n    print()\n    # print(\"INPUT: \", X_test[i])\n    prediction = model.forward(X_test[i])\n    print(\"PREDICTION: \", prediction)\n    print(\"ACTUAL: \", y_test[i])\n\n    mse = (y_test[i] - prediction) ** 2\n    rmse = np.sqrt(np.mean(mse))\n    predictions.append(prediction)\n    rmses.append(rmse)\n\nprint(\"Experiment 1 - Average Root Mean Squared Error (RMSE):\", np.mean(rmses))","block_group":"935a4e5122184aa3b181f3e52ca5245d","execution_count":null,"outputs":[{"name":"stdout","text":"\nPREDICTION:  [24.06129135  2.29447884  0.          0.        ]\nACTUAL:  [3.   3.04 2.99 2.99]\n\nPREDICTION:  [3.82425067 0.         0.         0.        ]\nACTUAL:  [3.01 3.03 2.97 3.  ]\n\nPREDICTION:  [1.04086995 0.         0.         0.        ]\nACTUAL:  [3.  3.  2.9 2.9]\n\nPREDICTION:  [14.86082602  0.          0.          0.        ]\nACTUAL:  [2.93 2.93 2.84 2.87]\n\nPREDICTION:  [23.51393225  0.          0.          0.        ]\nACTUAL:  [2.82 2.85 2.8  2.8 ]\n\nPREDICTION:  [24.33399972  0.          0.          0.        ]\nACTUAL:  [2.7  2.92 2.7  2.92]\n\nPREDICTION:  [30.34738018  0.          0.          0.        ]\nACTUAL:  [2.92 3.   2.92 3.  ]\n\nPREDICTION:  [6.03133162 0.         0.         0.        ]\nACTUAL:  [3.   3.   2.85 2.9 ]\n\nPREDICTION:  [4.76813199 0.         0.         0.        ]\nACTUAL:  [2.84 3.   2.84 2.93]\n\nPREDICTION:  [10.07627643  0.          0.          0.        ]\nACTUAL:  [3.   3.14 3.   3.  ]\n\nPREDICTION:  [3.16104409e+01 1.58567852e-02 0.00000000e+00 0.00000000e+00]\nACTUAL:  [2.89 3.08 2.8  2.96]\n\nPREDICTION:  [8.25207013 2.39837096 0.         0.        ]\nACTUAL:  [2.97 3.02 2.93 2.95]\n\nPREDICTION:  [14.07909421  0.          0.          0.        ]\nACTUAL:  [2.98 3.   2.95 2.96]\n\nPREDICTION:  [25.14343503  3.05975707  0.          0.        ]\nACTUAL:  [2.92 2.98 2.83 2.83]\n\nPREDICTION:  [25.08371847  8.59288634  0.          0.12565334]\nACTUAL:  [2.88 2.88 2.84 2.87]\n\nPREDICTION:  [19.08392331  6.82843773  0.          0.        ]\nACTUAL:  [2.87 2.88 2.86 2.87]\n\nPREDICTION:  [15.81601205  1.30974433  0.          0.        ]\nACTUAL:  [2.85 2.95 2.85 2.91]\n\nPREDICTION:  [1.12619322 0.         0.         0.        ]\nACTUAL:  [2.9  2.95 2.9  2.92]\n\nPREDICTION:  [4.36742022 0.         0.         0.        ]\nACTUAL:  [2.88 2.92 2.85 2.9 ]\n\nPREDICTION:  [10.66563787  0.          0.          0.        ]\nACTUAL:  [2.86 2.92 2.85 2.89]\n\nPREDICTION:  [10.72959709  0.          0.          0.        ]\nACTUAL:  [2.93 2.95 2.89 2.95]\n\nPREDICTION:  [24.43384867  0.          0.          0.        ]\nACTUAL:  [2.97 2.99 2.93 2.98]\n\nPREDICTION:  [11.85479796  3.17013327  0.          0.        ]\nACTUAL:  [2.97 3.06 2.96 2.97]\n\nPREDICTION:  [12.15334499  0.          0.          0.        ]\nACTUAL:  [3.02 3.02 2.93 2.93]\n\nPREDICTION:  [20.01457669  0.          0.          0.        ]\nACTUAL:  [2.86 2.93 2.84 2.84]\n\nPREDICTION:  [10.45264746  0.11131485  0.          0.        ]\nACTUAL:  [2.86 2.91 2.71 2.71]\n\nPREDICTION:  [7.51627245 0.         0.         1.58972901]\nACTUAL:  [2.67 2.77 2.62 2.68]\n\nPREDICTION:  [15.02246896  0.          0.          0.        ]\nACTUAL:  [2.65 2.73 2.65 2.67]\n\nPREDICTION:  [13.99962999  0.          0.          0.        ]\nACTUAL:  [2.66 2.73 2.66 2.7 ]\nExperiment 1 - Average Root Mean Squared Error (RMSE): 6.751372616348283\n","output_type":"stream"}]},{"cell_type":"code","metadata":{"source_hash":"2503dc06","execution_start":1699017527726,"execution_millis":52,"deepnote_to_be_reexecuted":true,"cell_id":"f250749626f5457b8b89e6c1eae93f6f","deepnote_cell_type":"code"},"source":"loaded_model = Sequential()\nloaded_model = loaded_model.load_model('TubesRNN/exp1.json')\nloaded_model.compile((4, 5), True)\nloaded_model.summary()\n\ntest = np.array([\n    [1, 2, 3, 4, 5],\n    [1, 2, 3, 4, 5],\n    [1, 2, 3, 4, 5],\n    [1, 2, 3, 4, 5],\n])\nprint(loaded_model.layers[0].weight.f.shape)\nprint(model.forward(test))\n\nloaded_model.save_model('TubesRNN/test.json')","block_group":"e5041cf00cd64b10be0dfea07aa0c342","execution_count":null,"outputs":[{"name":"stdout","text":"Model Summary:\n+------------+--------------+-----------+\n| Nama Layer | Output Shape | Parameter |\n+------------+--------------+-----------+\n|    LSTM    |      64      |   17920   |\n|   Dense    |      32      |    2080   |\n|   Dense    |      4       |    132    |\n+------------+--------------+-----------+\nTotal Parameters: 20132\n(64, 5)\n","output_type":"stream"},{"output_type":"error","ename":"ValueError","evalue":"shapes (4,) and (5,) not aligned: 4 (dim 0) != 5 (dim 0)","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn [17], line 13\u001b[0m\n\u001b[1;32m      6\u001b[0m test \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\n\u001b[1;32m      7\u001b[0m     [\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m],\n\u001b[1;32m      8\u001b[0m     [\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m],\n\u001b[1;32m      9\u001b[0m     [\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m],\n\u001b[1;32m     10\u001b[0m     [\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m],\n\u001b[1;32m     11\u001b[0m ])\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(loaded_model\u001b[38;5;241m.\u001b[39mlayers[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39mf\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     15\u001b[0m loaded_model\u001b[38;5;241m.\u001b[39msave_model(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTubesRNN/test.json\u001b[39m\u001b[38;5;124m'\u001b[39m)\n","Cell \u001b[0;32mIn [6], line 12\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, inp)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, inp: np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[0;32m---> 12\u001b[0m         inp \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43minp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m inp\n","Cell \u001b[0;32mIn [4], line 52\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[0;34m(self, input_data)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m unit_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munits):\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;66;03m# Loop through all rows\u001b[39;00m\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m row_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_shape[\u001b[38;5;241m0\u001b[39m]):\n\u001b[1;32m     51\u001b[0m         \u001b[38;5;66;03m# Calculate forget gate\u001b[39;00m\n\u001b[0;32m---> 52\u001b[0m         ft \u001b[38;5;241m=\u001b[39m sigmoid(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf\u001b[49m\u001b[43m[\u001b[49m\u001b[43munit_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_data\u001b[49m\u001b[43m[\u001b[49m\u001b[43mrow_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreccurent_weight\u001b[38;5;241m.\u001b[39mf[unit_idx], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mht) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias\u001b[38;5;241m.\u001b[39mf[unit_idx])\n\u001b[1;32m     53\u001b[0m         \u001b[38;5;66;03m# Calculate input gate\u001b[39;00m\n\u001b[1;32m     54\u001b[0m         it \u001b[38;5;241m=\u001b[39m sigmoid(np\u001b[38;5;241m.\u001b[39mdot(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39mi[unit_idx], input_data[row_idx]) \u001b[38;5;241m+\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreccurent_weight\u001b[38;5;241m.\u001b[39mi[unit_idx], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mht) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias\u001b[38;5;241m.\u001b[39mi[unit_idx])\n","File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: shapes (4,) and (5,) not aligned: 4 (dim 0) != 5 (dim 0)"]}]},{"cell_type":"markdown","source":"<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=61bb34cb-2316-475c-9595-96cf5c0e1564' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,PD94bWwgdmVyc2lvbj0iMS4wIiBlbmNvZGluZz0iVVRGLTgiPz4KPHN2ZyB3aWR0aD0iODBweCIgaGVpZ2h0PSI4MHB4IiB2aWV3Qm94PSIwIDAgODAgODAiIHZlcnNpb249IjEuMSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIiB4bWxuczp4bGluaz0iaHR0cDovL3d3dy53My5vcmcvMTk5OS94bGluayI+CiAgICA8IS0tIEdlbmVyYXRvcjogU2tldGNoIDU0LjEgKDc2NDkwKSAtIGh0dHBzOi8vc2tldGNoYXBwLmNvbSAtLT4KICAgIDx0aXRsZT5Hcm91cCAzPC90aXRsZT4KICAgIDxkZXNjPkNyZWF0ZWQgd2l0aCBTa2V0Y2guPC9kZXNjPgogICAgPGcgaWQ9IkxhbmRpbmciIHN0cm9rZT0ibm9uZSIgc3Ryb2tlLXdpZHRoPSIxIiBmaWxsPSJub25lIiBmaWxsLXJ1bGU9ImV2ZW5vZGQiPgogICAgICAgIDxnIGlkPSJBcnRib2FyZCIgdHJhbnNmb3JtPSJ0cmFuc2xhdGUoLTEyMzUuMDAwMDAwLCAtNzkuMDAwMDAwKSI+CiAgICAgICAgICAgIDxnIGlkPSJHcm91cC0zIiB0cmFuc2Zvcm09InRyYW5zbGF0ZSgxMjM1LjAwMDAwMCwgNzkuMDAwMDAwKSI+CiAgICAgICAgICAgICAgICA8cG9seWdvbiBpZD0iUGF0aC0yMCIgZmlsbD0iIzAyNjVCNCIgcG9pbnRzPSIyLjM3NjIzNzYyIDgwIDM4LjA0NzY2NjcgODAgNTcuODIxNzgyMiA3My44MDU3NTkyIDU3LjgyMTc4MjIgMzIuNzU5MjczOSAzOS4xNDAyMjc4IDMxLjY4MzE2ODMiPjwvcG9seWdvbj4KICAgICAgICAgICAgICAgIDxwYXRoIGQ9Ik0zNS4wMDc3MTgsODAgQzQyLjkwNjIwMDcsNzYuNDU0OTM1OCA0Ny41NjQ5MTY3LDcxLjU0MjI2NzEgNDguOTgzODY2LDY1LjI2MTk5MzkgQzUxLjExMjI4OTksNTUuODQxNTg0MiA0MS42NzcxNzk1LDQ5LjIxMjIyODQgMjUuNjIzOTg0Niw0OS4yMTIyMjg0IEMyNS40ODQ5Mjg5LDQ5LjEyNjg0NDggMjkuODI2MTI5Niw0My4yODM4MjQ4IDM4LjY0NzU4NjksMzEuNjgzMTY4MyBMNzIuODcxMjg3MSwzMi41NTQ0MjUgTDY1LjI4MDk3Myw2Ny42NzYzNDIxIEw1MS4xMTIyODk5LDc3LjM3NjE0NCBMMzUuMDA3NzE4LDgwIFoiIGlkPSJQYXRoLTIyIiBmaWxsPSIjMDAyODY4Ij48L3BhdGg+CiAgICAgICAgICAgICAgICA8cGF0aCBkPSJNMCwzNy43MzA0NDA1IEwyNy4xMTQ1MzcsMC4yNTcxMTE0MzYgQzYyLjM3MTUxMjMsLTEuOTkwNzE3MDEgODAsMTAuNTAwMzkyNyA4MCwzNy43MzA0NDA1IEM4MCw2NC45NjA0ODgyIDY0Ljc3NjUwMzgsNzkuMDUwMzQxNCAzNC4zMjk1MTEzLDgwIEM0Ny4wNTUzNDg5LDc3LjU2NzA4MDggNTMuNDE4MjY3Nyw3MC4zMTM2MTAzIDUzLjQxODI2NzcsNTguMjM5NTg4NSBDNTMuNDE4MjY3Nyw0MC4xMjg1NTU3IDM2LjMwMzk1NDQsMzcuNzMwNDQwNSAyNS4yMjc0MTcsMzcuNzMwNDQwNSBDMTcuODQzMDU4NiwzNy43MzA0NDA1IDkuNDMzOTE5NjYsMzcuNzMwNDQwNSAwLDM3LjczMDQ0MDUgWiIgaWQ9IlBhdGgtMTkiIGZpbGw9IiMzNzkzRUYiPjwvcGF0aD4KICAgICAgICAgICAgPC9nPgogICAgICAgIDwvZz4KICAgIDwvZz4KPC9zdmc+' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>","metadata":{"created_in_deepnote_cell":true,"deepnote_cell_type":"markdown"}}],"nbformat":4,"nbformat_minor":0,"metadata":{"deepnote":{},"orig_nbformat":2,"deepnote_notebook_id":"7ddf328a7c834d7b951ebff9494c6ac3","deepnote_persisted_session":{"createdAt":"2023-11-03T13:02:38.747Z"},"deepnote_execution_queue":[]}}