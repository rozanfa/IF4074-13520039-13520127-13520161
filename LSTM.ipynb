{"cells":[{"cell_type":"code","metadata":{"source_hash":"61d633bc","execution_start":1699026642397,"execution_millis":3221,"deepnote_to_be_reexecuted":false,"cell_id":"debeb8a993d747a6be55894b39d51731","deepnote_cell_type":"code"},"source":"!pip install prettytable","block_group":"356cc00b05ad461caeefd206894a8e42","execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: prettytable in /root/venv/lib/python3.9/site-packages (3.9.0)\nRequirement already satisfied: wcwidth in /shared-libs/python3.9/py-core/lib/python3.9/site-packages (from prettytable) (0.2.5)\n\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","metadata":{"source_hash":"57814848","execution_start":1699026645620,"execution_millis":15,"deepnote_to_be_reexecuted":false,"cell_id":"734ae5d970bb440681c909d5daa1193a","deepnote_cell_type":"code"},"source":"import numpy as np\nimport pandas as pd\nfrom math import sqrt\nimport json\n\ndef sigmoid(X):\n    \"\"\"Sigmoid activation function\"\"\"\n    return 1 / (1 + np.exp(-X))\n\ndef relu(X):\n    \"\"\"ReLU activation function\"\"\"\n    return np.maximum(0, X)\n\ndef tanh(X):\n    \"\"\"TanH activaction function\"\"\"\n    return np.tanh(X)","block_group":"734ae5d970bb440681c909d5daa1193a","execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"source_hash":"ff30cff","execution_start":1699026645627,"execution_millis":13,"deepnote_to_be_reexecuted":false,"cell_id":"3aa11bbb82d74a6e8e2eddcd1c5d09e6","deepnote_cell_type":"code"},"source":"class Layer:\n    input_shape = None\n    output_shape = None\n    \n    def forward():\n        pass\n\nnp.random.seed(13520161)","block_group":"8bcbbb9190ba4f278f722601ccb44d54","execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"source_hash":"3fb4d5c2","execution_start":1699026645650,"execution_millis":27,"deepnote_to_be_reexecuted":false,"cell_id":"b29c9ab3f0154c238f8b946efb2fca8c","deepnote_cell_type":"code"},"source":"from typing import Literal\n\nclass LSTM(Layer):\n    class Weight:\n        \"\"\"Weight class for LSTM\"\"\"\n        def __init__(self, f, i, c, o) -> None:\n            self.f = f\n            self.i = i\n            self.c = c\n            self.o = o\n\n    def __init__(self, units: int) -> None:\n        super().__init__()\n        self.units = units\n\n    def _compile(self, input_shape: int, from_load: bool = False):\n        self.input_shape = input_shape # (Row, Feature)\n        self.output_shape = self.units\n        \n        self.weight = self.Weight(\n            np.random.randn(self.units, self.input_shape[1]),\n            np.random.randn(self.units, self.input_shape[1]),\n            np.random.randn(self.units, self.input_shape[1]),\n            np.random.randn(self.units, self.input_shape[1]))\n        \n        self.bias = self.Weight(\n            np.random.randn(self.units),\n            np.random.randn(self.units),\n            np.random.randn(self.units),\n            np.random.randn(self.units)) # b\n        \n        self.reccurent_weight = self.Weight(\n            np.random.randn(self.output_shape, self.output_shape),\n            np.random.randn(self.output_shape, self.output_shape),\n            np.random.randn(self.output_shape, self.output_shape),\n            np.random.randn(self.output_shape, self.output_shape)) # W\n        \n        self.timestep = np.zeros(self.units)\n        self.ct = np.zeros(self.units)\n        self.ht = np.zeros(self.units)\n\n        return self.output_shape\n\n    def forward(self, input_data: np.ndarray):\n        \"\"\"Forward propagation\"\"\"\n        \n        # Loop through all units:\n        for unit_idx in range(self.units):\n            # Loop through all rows\n            for row_idx in range(self.input_shape[0]):\n                # Calculate forget gate\n                ft = sigmoid(np.dot(self.weight.f[unit_idx], input_data[row_idx]) + np.dot(self.reccurent_weight.f[unit_idx], self.ht) + self.bias.f[unit_idx])\n                # Calculate input gate\n                it = sigmoid(np.dot(self.weight.i[unit_idx], input_data[row_idx]) + np.dot(self.reccurent_weight.i[unit_idx], self.ht) + self.bias.i[unit_idx])\n                # Calculate candidate\n                ct_ = tanh(np.dot(self.weight.c[unit_idx], input_data[row_idx]) + np.dot(self.reccurent_weight.c[unit_idx], self.ht) + self.bias.c[unit_idx])\n                # Calculate output gate\n                ot = sigmoid(np.dot(self.weight.o[unit_idx], input_data[row_idx]) + np.dot(self.reccurent_weight.o[unit_idx], self.ht) + self.bias.o[unit_idx])\n                \n                # Calculate cell state\n                self.ct[unit_idx] = ft * self.ct[unit_idx] + it * ct_\n\n                # Calculate hidden state\n                self.ht[unit_idx] = ot * tanh(self.ct[unit_idx])\n                self.timestep[unit_idx] += 1\n\n        return self.ht\n\n    def get_params_count(self):\n        return self.bias.f.size * 4 + self.weight.f.size * 4 + self.reccurent_weight.f.size * 4\n\n    def set_params(self, params):\n        self.weight.f = np.array(params[\"W_f\"])\n        self.weight.i = np.array(params[\"W_i\"])\n        self.weight.c = np.array(params[\"W_c\"])\n        self.weight.o = np.array(params[\"W_o\"])\n        self.reccurent_weight.f = np.array(params[\"U_f\"])\n        self.reccurent_weight.i = np.array(params[\"U_i\"])\n        self.reccurent_weight.c = np.array(params[\"U_c\"])\n        self.reccurent_weight.o = np.array(params[\"U_o\"])\n        self.bias.f = np.array(params[\"b_f\"])\n        self.bias.i = np.array(params[\"b_i\"])\n        self.bias.c = np.array(params[\"b_c\"])\n        self.bias.o = np.array(params[\"b_o\"])\n\n    def get_params(self):\n        params = {\n            \"units\": self.units,\n            \"W_i\": np.transpose(self.weight.i).tolist(),\n            \"W_f\": np.transpose(self.weight.f).tolist(),\n            \"W_c\": np.transpose(self.weight.c).tolist(),\n            \"W_o\": np.transpose(self.weight.o).tolist(),\n            \"U_i\": self.reccurent_weight.i.tolist(),\n            \"U_f\": self.reccurent_weight.f.tolist(),\n            \"U_c\": self.reccurent_weight.c.tolist(),\n            \"U_o\": self.reccurent_weight.o.tolist(),\n            \"b_i\": self.bias.i.tolist(),\n            \"b_f\": self.bias.f.tolist(),\n            \"b_c\": self.bias.c.tolist(),\n            \"b_o\": self.bias.o.tolist(),\n        }\n        return params\n\n\nif __name__ == \"__main__\":\n    model = LSTM(1)\n    model._compile((2, 2))\n    model.weight.f = np.array([[0.5, 0.75]])\n    model.weight.i = np.array([[0.81, 0.2]])\n    model.weight.c = np.array([[0.35, 0.45]])\n    model.weight.o = np.array([[0.4, 0.6]])\n    model.reccurent_weight.f = np.array([[0.3]])\n    model.reccurent_weight.i = np.array([[0.7]])\n    model.reccurent_weight.c = np.array([[0.35]])\n    model.reccurent_weight.o = np.array([[0.4]])\n    model.bias.f = np.array([0.4])\n    model.bias.i = np.array([0.55])\n    model.bias.c = np.array([0.25])\n    model.bias.o = np.array([0.5])\n    print(model.forward(np.array([[0.5, 3], [1, 2]])))\n\n    new_model = LSTM(64)\n    new_model._compile((4, 5))\n    print(new_model.weight.f.shape)\n    print(new_model.output_shape)","block_group":"918187936cf342e2a4fc2adccf46c92d","execution_count":4,"outputs":[{"name":"stdout","text":"[0.83602558]\n(64, 5)\n64\n","output_type":"stream"}]},{"cell_type":"code","metadata":{"source_hash":"da4345a7","execution_start":1699026645677,"execution_millis":19,"deepnote_to_be_reexecuted":false,"cell_id":"84a87f243fc6440f9b2e27a3f05d6884","deepnote_cell_type":"code"},"source":"class Dense(Layer):\n    def __init__(self, units: int, activation: Literal[\"sigmoid\", \"relu\"] = \"relu\") -> None:\n        \"\"\"\n        Dense layer\n\n        Parameters\n        ----------\n        units : int\n            Number of neuron\n        activation : str\n            Activation function (\"sigmoid\" or \"relu\")\n        \"\"\"\n        self.units = units\n        self.activation = activation\n\n        self.output_shape = units\n\n    def _compile(self, shape, from_load: bool = False):\n        # Initialize weight & bias\n        self.input_size = shape\n\n        if not from_load:\n            self.weights = np.random.randn(shape, self.units)\n            self.bias = np.random.randn(self.units)\n        \n        return self.output_shape\n\n    @staticmethod\n    def __activate(X: np.ndarray, activation: Literal[\"sigmoid\", \"relu\"] = \"relu\") -> np.ndarray:\n        \"\"\"Activation function\n\n        Parameters\n        ----------\n        X : np.ndarray\n            Input data\n        activation : str\n            Activation function to be used\n        \"\"\"\n        if activation == \"sigmoid\":\n            f = lambda x: sigmoid(x)\n        elif activation == \"relu\":\n            f = lambda x: relu(x)\n        else:\n            raise ValueError(\"Activation function not supported\")\n        return f(X)\n\n    def forward(self, input_data: np.ndarray) -> np.ndarray:\n        \"\"\"Forward pass of Dense layer\n\n        Parameters\n        ----------\n        input_data : np.ndarray\n            Input data to be passed through the layer\n        \"\"\"\n        \n        # Linear transformation (dot product input x weights)\n        self.input_data = input_data\n        self.output = np.dot(input_data, self.weights) + self.bias\n        \n        # Activation function\n        output = Dense.__activate(self.output, self.activation)\n        \n        return output\n\n    def get_params_count(self):\n        return self.input_size * self.units + self.units\n\n    def set_params(self, params):\n        self.weights = np.array(params[\"kernel\"])\n        self.bias = np.array(params[\"bias\"])\n\n    def get_params(self):\n        params = {\n            \"units\": self.units,\n            \"activation\": self.activation,\n            \"kernel\": self.weights.tolist(),\n            \"bias\": self.bias.tolist()\n        }\n        return params\n\n    def set_params(self, params):\n        self.units = params[\"units\"]\n        self.activation = params[\"activation\"]\n        self.weights = np.array(params[\"weights\"])\n        self.bias = np.array(params[\"bias\"])","block_group":"7b235ac1d2b94995b7d4d4bc35aba767","execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"source_hash":"3ba589b8","execution_start":1699026645707,"execution_millis":17,"deepnote_to_be_reexecuted":false,"cell_id":"d27de66ad89947bca4194211394fcb8a","deepnote_cell_type":"code"},"source":"from prettytable import PrettyTable\n\nclass Sequential:\n    def __init__(self, layers: list[object] = []):\n        self.layers = layers\n\n    def add(self, layer: Layer) -> None:\n        self.layers.append(layer)\n\n    def forward(self, inp: np.ndarray) -> np.ndarray:\n        for layer in self.layers:\n            inp = layer.forward(inp)\n        return inp\n\n    def predict(self, img: np.ndarray) -> np.ndarray:\n        return self.forward(img)\n\n    def compile(self, input_shape, from_load: bool = False):\n        assert len(self.layers) > 0, \"Tambah layer terlebih dahulu\"\n        for layer in self.layers:\n            layer._compile(input_shape, from_load)\n            input_shape = layer.output_shape\n\n    def summary(self):\n        total_params = 0\n        print(\"Model Summary:\")\n\n        table = PrettyTable([\"Nama Layer\", \"Output Shape\", \"Parameter\"])\n        for i, layer in enumerate(self.layers):\n            layer_name = layer.__class__.__name__\n            output_shape = layer.output_shape if hasattr(layer, \"output_shape\") else None\n            params = layer.get_params_count() if hasattr(layer, \"get_params_count\") else 0\n            total_params += params\n            \n            table.add_row([layer_name, output_shape, params])\n\n        print(table)\n        print(f\"Total Parameters: {total_params}\")\n\n    # Save Model\n    def save_model(self, filepath):\n        model_list = []\n        for layer in self.layers:\n            layer_dict = {\n                \"type\": layer.__class__.__name__.lower(),\n                \"params\": layer.get_params()\n            }\n            model_list.append(layer_dict)\n\n        with open(filepath, 'w') as file:\n            json.dump(model_list, file, indent=4) \n\n    def load_model(self, filename, input_shape):\n        with open(filename, 'r') as json_file:\n            model_list = json.load(json_file)\n\n        layers = []\n        for layer_params in model_list:\n            layer_type = layer_params[\"type\"]\n            layer_args = layer_params[\"params\"]\n\n            if layer_type == \"dense\":\n                if \"units\" in layer_args:\n                    units_size = layer_args[\"units\"]\n                else:\n                    units_size = len(layer_args[\"bias\"])\n\n                activation = layer_args.get(\"activation\")\n                if activation != None:\n                    layer = Dense(units=units_size, activation=activation)\n                else:\n                    layer = Dense(units=units_size)\n            elif layer_type == \"lstm\":\n                if \"units\" in layer_args:\n                    units_size = layer_args[\"units\"]\n                else:\n                    units_size = len(layer_args[\"b_f\"])\n\n                layer = LSTM(units=units_size)\n                layer._compile(input_shape)\n                layer.set_params(layer_args)\n            else:\n                raise ValueError(f\"Unsupported layer type: {layer_type}\")\n\n            layers.append(layer)\n\n        model = Sequential(layers)\n        model.compile(input_shape) \n        return model","block_group":"a5271b363c9a4bb2a03e0c0a4681aa57","execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"source_hash":"5eb963cd","execution_start":1699026645774,"execution_millis":11,"deepnote_to_be_reexecuted":false,"cell_id":"03aab19cc0144cef855235c4d9f3de27","deepnote_cell_type":"code"},"source":"# split for getting next day result\ndef split_sequence(sequence, n_steps):\n\tX, y = list(), list()\n\tfor i in range(len(sequence)):\n\t\t# find the end of this pattern\n\t\tend_ix = i + n_steps\n\t\t# check if we are beyond the sequence\n\t\tif end_ix > len(sequence)-1:\n\t\t\tbreak\n\t\t# gather input and output parts of the pattern\n\t\tseq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\n\t\tX.append(seq_x)\n\t\ty.append(seq_y)\n\treturn np.array(X), np.array(y)","block_group":"7cb6a6a4aa3b4ed59ec466488b865176","execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"source_hash":"c7511af6","execution_start":1699026645775,"execution_millis":58,"deepnote_to_be_reexecuted":false,"cell_id":"b1711d56be3042e590e474fe1534f921","deepnote_cell_type":"code"},"source":"raw_train = pd.read_csv(\"TubesRNN/Train_stock_market.csv\")\ntest = pd.read_csv(\"TubesRNN/Test_stock_market.csv\")\n\ntrain_date = raw_train[\"Date\"]\ntrain_date = pd.to_datetime(train_date)\n\ntrain = raw_train.drop(\"Date\", axis=1)\n\ntrain['Date'] = train_date\ntest['Date'] = pd.to_datetime(test['Date'])\n\n# print(test.head())\n# print(train.head())\n\n# Take relevant columns\ntrain = train[['Date', 'Open', 'High', 'Low', 'Close']]\ntest = test[['Date', 'Open', 'High', 'Low', 'Close']]","block_group":"da485cb58ab74ba2a35d94937e208325","execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"source_hash":"9bd7ef0e","execution_start":1699026645821,"execution_millis":27,"deepnote_to_be_reexecuted":false,"cell_id":"b5fae07bcab84f259ded3c95cb857198","deepnote_cell_type":"code"},"source":"# Experiment 1\nn_steps = 10  # Number of days\nX_train, y_train = split_sequence(train[['Open', 'High', 'Low', 'Close']].values, n_steps)\nX_test, y_test = split_sequence(test[['Open', 'High', 'Low', 'Close']].values, n_steps)\n\n# Create model\nmodel = Sequential([])\nmodel.add(LSTM(units=64))\nmodel.add(Dense(units=32, activation=\"relu\"))\nmodel.add(Dense(units=4))  # 4 output\n\ninput_shape = (X_test.shape[1], X_test.shape[2])  # (n_steps, number of features)\n\n# Compile\nmodel.compile(input_shape, from_load=False)","block_group":"60493412db924f678343b6667bc0fe39","execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"source_hash":"3890e1f0","execution_start":1699026645885,"execution_millis":11,"deepnote_to_be_reexecuted":false,"cell_id":"c4cf8b1b2f1c4becad5dccb62d77f37a","deepnote_cell_type":"code"},"source":"# Experiment 2\nn_steps_2 = 35  # Number of days\nX_train_2, y_train_2 = split_sequence(train[['Open', 'High', 'Low', 'Close']].values, n_steps_2)\nX_test_2, y_test_2 = split_sequence(test[['Open', 'High', 'Low', 'Close']].values, n_steps_2)\n\n# Create model\nmodel_2 = Sequential([])\nmodel_2.add(LSTM(units=64))\nmodel_2.add(Dense(units=32, activation=\"relu\"))\nmodel_2.add(Dense(units=4))  # 4 output\n\ninput_shape_2 = (X_test_2.shape[1], X_test_2.shape[2])  # (n_steps, number of features)\n\n# Compile\nmodel_2.compile(input_shape_2, from_load=False)","block_group":"2f5c53908d774d9db6962a27c62c7015","execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"source_hash":"1d57fbda","execution_start":1699026645886,"execution_millis":43,"deepnote_to_be_reexecuted":false,"cell_id":"d57bde1c0d994d32a972dc944f6343a1","deepnote_cell_type":"code"},"source":"# Experiment 3\nn_steps_3 = 25  # Number of days\nX_train_3, y_train_3 = split_sequence(train[['Open', 'High', 'Low', 'Close']].values, n_steps_3)\nX_test_3, y_test_3 = split_sequence(test[['Open', 'High', 'Low', 'Close']].values, n_steps_3)\n\n# Create model\nmodel_3 = Sequential([])\nmodel_3.add(LSTM(units=64))\nmodel_3.add(Dense(units=32, activation=\"relu\"))\nmodel_3.add(Dense(units=4))  # 4 output\n\ninput_shape_3 = (X_test_3.shape[1], X_test_3.shape[2])  # (n_steps, number of features)\n\n# Compile\nmodel_3.compile(input_shape_3, from_load=False)","block_group":"da12757018ab446ea555836b669d8228","execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"source_hash":"6c763782","execution_start":1699026645925,"execution_millis":219,"deepnote_to_be_reexecuted":false,"cell_id":"90db603c07a64353b7c2c7c3687ace4c","deepnote_cell_type":"code"},"source":"model.save_model('TubesRNN/exp1.json')\nmodel_2.save_model('TubesRNN/exp2.json')\nmodel_3.save_model('TubesRNN/exp3.json')\n\nmodel_exp1 = Sequential([])\nmodel_exp1 = model_exp1.load_model('TubesRNN/exp1.json', input_shape)\n\nmodel_exp2 = Sequential([])\nmodel_exp2 = model_exp2.load_model('TubesRNN/exp2.json', input_shape_2)\n\nmodel_exp3 = Sequential([])\nmodel_exp3 = model_exp3.load_model('TubesRNN/exp3.json', input_shape_3)","block_group":"151a0d7156334effaf4a4d75283cb154","execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"source_hash":"83b42657","execution_start":1699026646120,"execution_millis":55,"deepnote_to_be_reexecuted":false,"cell_id":"2ad5e86c7d214c4694bcc4be4475c723","deepnote_cell_type":"code"},"source":"# model.summary()\nmodel_exp1.summary()\nmodel_exp2.summary()\nmodel_exp3.summary()","block_group":"df5cd777e6904646bb83018b9dcdc294","execution_count":13,"outputs":[{"name":"stdout","text":"Model Summary:\n+------------+--------------+-----------+\n| Nama Layer | Output Shape | Parameter |\n+------------+--------------+-----------+\n|    LSTM    |      64      |   17664   |\n|   Dense    |      32      |    2080   |\n|   Dense    |      4       |    132    |\n+------------+--------------+-----------+\nTotal Parameters: 19876\nModel Summary:\n+------------+--------------+-----------+\n| Nama Layer | Output Shape | Parameter |\n+------------+--------------+-----------+\n|    LSTM    |      64      |   17664   |\n|   Dense    |      32      |    2080   |\n|   Dense    |      4       |    132    |\n+------------+--------------+-----------+\nTotal Parameters: 19876\nModel Summary:\n+------------+--------------+-----------+\n| Nama Layer | Output Shape | Parameter |\n+------------+--------------+-----------+\n|    LSTM    |      64      |   17664   |\n|   Dense    |      32      |    2080   |\n|   Dense    |      4       |    132    |\n+------------+--------------+-----------+\nTotal Parameters: 19876\n","output_type":"stream"}]},{"cell_type":"code","metadata":{"source_hash":"df841cc9","execution_start":1699026646121,"execution_millis":368,"deepnote_to_be_reexecuted":false,"cell_id":"bfbfd2af92d847a78b17899443d8fac9","deepnote_cell_type":"code"},"source":"predictions = []\nrmses = []\nfor i in range(len(X_test)):\n    print()\n    # print(\"INPUT: \", X_test[i])\n    prediction = model.forward(X_test[i])\n    print(\"PREDICTION: \", prediction)\n    print(\"ACTUAL: \", y_test[i])\n\n    mse = (y_test[i] - prediction) ** 2\n    rmse = np.sqrt(np.mean(mse))\n    predictions.append(prediction)\n    rmses.append(rmse)\n\nprint(\"Experiment 1 - Average Root Mean Squared Error (RMSE):\", np.mean(rmses))","block_group":"935a4e5122184aa3b181f3e52ca5245d","execution_count":14,"outputs":[{"name":"stdout","text":"\nPREDICTION:  [37.52861608  2.33685708  0.         11.77490141]\nACTUAL:  [3.   3.04 2.99 2.99]\n\nPREDICTION:  [48.62681953 10.17832562  0.          8.98229644]\nACTUAL:  [3.01 3.03 2.97 3.  ]\n\nPREDICTION:  [19.32281148  0.23497658  0.          0.        ]\nACTUAL:  [3.  3.  2.9 2.9]\n\nPREDICTION:  [45.61959959  4.62118873  0.          9.20185597]\nACTUAL:  [2.93 2.93 2.84 2.87]\n\nPREDICTION:  [16.64390096  0.86286975  0.          0.        ]\nACTUAL:  [2.82 2.85 2.8  2.8 ]\n\nPREDICTION:  [46.42546436  6.94982722  0.          8.90203392]\nACTUAL:  [2.7  2.92 2.7  2.92]\n\nPREDICTION:  [16.85568539  1.22314216  0.          0.        ]\nACTUAL:  [2.92 3.   2.92 3.  ]\n\nPREDICTION:  [17.63291786  0.          0.          0.        ]\nACTUAL:  [3.   3.   2.85 2.9 ]\n\nPREDICTION:  [13.81915582  0.          0.          1.72340823]\nACTUAL:  [2.84 3.   2.84 2.93]\n\nPREDICTION:  [45.02360191  8.49993896  0.          7.37979516]\nACTUAL:  [3.   3.14 3.   3.  ]\n\nPREDICTION:  [17.05672709  2.67935941  0.          0.        ]\nACTUAL:  [2.89 3.08 2.8  2.96]\n\nPREDICTION:  [17.37851793  0.          0.          0.        ]\nACTUAL:  [2.97 3.02 2.93 2.95]\n\nPREDICTION:  [12.50599133  0.          0.          0.        ]\nACTUAL:  [2.98 3.   2.95 2.96]\n\nPREDICTION:  [44.65027728  8.3743122   0.          5.81343977]\nACTUAL:  [2.92 2.98 2.83 2.83]\n\nPREDICTION:  [17.29289249  3.43894002  0.          0.        ]\nACTUAL:  [2.88 2.88 2.84 2.87]\n\nPREDICTION:  [16.79886156  0.          0.          0.        ]\nACTUAL:  [2.87 2.88 2.86 2.87]\n\nPREDICTION:  [11.63923038  0.          0.          0.        ]\nACTUAL:  [2.85 2.95 2.85 2.91]\n\nPREDICTION:  [42.89807215  8.61902289  0.          4.3440703 ]\nACTUAL:  [2.9  2.95 2.9  2.92]\n\nPREDICTION:  [16.74817724  4.4452325   0.          0.        ]\nACTUAL:  [2.88 2.92 2.85 2.9 ]\n\nPREDICTION:  [26.50534247  0.          0.          2.09480092]\nACTUAL:  [2.86 2.92 2.85 2.89]\n\nPREDICTION:  [42.49962568 11.26816484  0.          3.46975908]\nACTUAL:  [2.93 2.95 2.89 2.95]\n\nPREDICTION:  [16.76080953  5.64849874  0.          0.        ]\nACTUAL:  [2.97 2.99 2.93 2.98]\n\nPREDICTION:  [13.05121431  0.          0.          0.        ]\nACTUAL:  [2.97 3.06 2.96 2.97]\n\nPREDICTION:  [11.08906211  0.          0.          0.        ]\nACTUAL:  [3.02 3.02 2.93 2.93]\n\nPREDICTION:  [42.43229076  9.30862977  0.          3.66679228]\nACTUAL:  [2.86 2.93 2.84 2.84]\n\nPREDICTION:  [16.61425452  4.90943146  0.          0.        ]\nACTUAL:  [2.86 2.91 2.71 2.71]\n\nPREDICTION:  [14.53390788  0.          0.          0.        ]\nACTUAL:  [2.67 2.77 2.62 2.68]\n\nPREDICTION:  [10.96564688  0.          0.          0.        ]\nACTUAL:  [2.65 2.73 2.65 2.67]\n\nPREDICTION:  [41.2806934  10.01098199  0.          3.78076974]\nACTUAL:  [2.66 2.73 2.66 2.7 ]\nExperiment 1 - Average Root Mean Squared Error (RMSE): 11.737717138952545\n","output_type":"stream"}]},{"cell_type":"code","metadata":{"source_hash":"9a3a237a","execution_start":1699026646484,"execution_millis":90,"deepnote_to_be_reexecuted":false,"cell_id":"46d973307385494ba6a9c7fd2d5cba5b","deepnote_cell_type":"code"},"source":"predictions = []\nrmses = []\nfor i in range(len(X_test_2)):\n    print()\n    # print(\"INPUT: \", X_test[i])\n    prediction = model.forward(X_test_2[i])\n    print(\"PREDICTION: \", prediction)\n    print(\"ACTUAL: \", y_test_2[i])\n\n    mse = (y_test_2[i] - prediction) ** 2\n    rmse = np.sqrt(np.mean(mse))\n    predictions.append(prediction)\n    rmses.append(rmse)\n\nprint(\"Experiment 2 - Average Root Mean Squared Error (RMSE):\", np.mean(rmses))","block_group":"8f055e61493c4b82a0f647caf67317b5","execution_count":15,"outputs":[{"name":"stdout","text":"\nPREDICTION:  [16.28277854  5.47102065  0.          0.        ]\nACTUAL:  [2.86 2.91 2.71 2.71]\n\nPREDICTION:  [30.73419301  0.          0.          4.99363672]\nACTUAL:  [2.67 2.77 2.62 2.68]\n\nPREDICTION:  [43.70423744 12.70686409  0.          4.25336412]\nACTUAL:  [2.65 2.73 2.65 2.67]\n\nPREDICTION:  [16.38445439  6.59553641  0.          0.        ]\nACTUAL:  [2.66 2.73 2.66 2.7 ]\nExperiment 2 - Average Root Mean Squared Error (RMSE): 12.465485066918605\n","output_type":"stream"}]},{"cell_type":"code","metadata":{"source_hash":"1a3915b6","execution_start":1699026646560,"execution_millis":213,"deepnote_to_be_reexecuted":false,"cell_id":"5909a0a567074edeb86874b28049e948","deepnote_cell_type":"code"},"source":"predictions = []\nrmses = []\nfor i in range(len(X_test_3)):\n    print()\n    # print(\"INPUT: \", X_test[i])\n    prediction = model.forward(X_test_3[i])\n    print(\"PREDICTION: \", prediction)\n    print(\"ACTUAL: \", y_test_3[i])\n\n    mse = (y_test_3[i] - prediction) ** 2\n    rmse = np.sqrt(np.mean(mse))\n    predictions.append(prediction)\n    rmses.append(rmse)\n\nprint(\"Experiment 3 - Average Root Mean Squared Error (RMSE):\", np.mean(rmses))","block_group":"c734f97e5eea492686f1d6d60103eab1","execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=61bb34cb-2316-475c-9595-96cf5c0e1564' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>","metadata":{"created_in_deepnote_cell":true,"deepnote_cell_type":"markdown"}}],"nbformat":4,"nbformat_minor":0,"metadata":{"deepnote":{},"orig_nbformat":2,"deepnote_notebook_id":"7ddf328a7c834d7b951ebff9494c6ac3","deepnote_persisted_session":{"createdAt":"2023-11-03T13:02:38.747Z"},"deepnote_execution_queue":[]}}